<!-- vscode-markdown-toc -->
<!-- * 1. [é¡¹ç›®ä»‹ç»](#)
* 2. [å®‰è£…æ•™ç¨‹](#-1)
* 3. [å¿«é€Ÿä¸Šæ‰‹é¢„è®­ç»ƒæ¨¡å‹](#-1)
* 4. [æ›´å¤šä»»åŠ¡](#-1)
* 5. [å¼€æºåè®®](#-1)
* 6. [è”ç³»æ–¹å¼](#-1) -->

<!-- vscode-markdown-toc-config
	numbering=true
	autoSave=true
	/vscode-markdown-toc-config -->
<!-- /vscode-markdown-toc -->

ç®€ä½“ä¸­æ–‡ï½œ[English](readme_en.md)
<p align="center">
  <img src="asserts/tentrans.png" width="200">
  </br>
  <a href="https://github.com/TenTrans/TenTrans/blob/master/LICENSE"><img alt="MIT License" src="https://img.shields.io/badge/License-MIT-blue" /></a>
  <a href="https://github.com/TenTrans/TenTrans/releases"><img alt="Latest Release" src="https://img.shields.io/badge/Release-v1.0-yellow" /></a>
  <a href="https://github.com/TenTrans/TenTrans/releases"><img alt="Latest Release" src="https://img.shields.io/badge/Language-Python-orange" /></a>
</p>


-------
## ğŸ”¥ é¡¹ç›®ä»‹ç»
TenTransæ˜¯ä¸€ä¸ªçµæ´»è½»é‡çš„è‡ªç„¶è¯­è¨€å¤„ç†è®­ç»ƒæ¡†æ¶ï¼Œ æ”¯æŒå¸¸è§çš„NLPä»»åŠ¡ï¼ˆåŒ…æ‹¬è‡ªç„¶è¯­è¨€ç†è§£ã€ç”Ÿæˆã€é¢„è®­ç»ƒï¼‰ã€‚ TenTransæœ‰ä»¥ä¸‹ç‰¹ç‚¹:

- ä»»åŠ¡åŸå­åŒ–ï¼š ç”¨æˆ·å¯ä»¥ä»»æ„ç»„åˆå„ç§NLPä»»åŠ¡è¿›è¡Œè”åˆè®­ç»ƒï¼Œ å„ä»»åŠ¡ä¹‹é—´çš„å‚æ•°å¯ä»¥ç»†ç²’åº¦åœ°å…±äº«ã€‚
- é«˜æ€§èƒ½è®­ç»ƒï¼š TenTransæ”¯æŒå¤šæœºå¤šå¡å¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œå·²åœ¨150Gä»¥ä¸Šçš„è¶…å¤§è§„æ¨¡è¯­æ–™ä¸Šè¿›è¡Œé¢„è®­ç»ƒéªŒè¯ã€‚
- å¤šè¯­è¨€åŠè·¨è¯­è¨€ï¼š TenTransæ”¯æŒè·¨è¯­è¨€é¢„è®­ç»ƒï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è¿ç§»å­¦ä¹ çš„æ–¹å¼è§£å†³ä½èµ„æºè¯­è¨€è¯­æ–™ä¸è¶³çš„é—®é¢˜ã€‚
- å·¥ä¸šåŒ–éƒ¨ç½²ï¼šTentransé…å¥—é«˜æ€§èƒ½çš„è§£ç å™¨ [TenTrans-Decoding](https://github.com/TenTrans/TenTrans-Decoding), å¯ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚

TenTransç›®å‰æ”¯æŒçš„NLPä»»åŠ¡åŒ…æ‹¬
- è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆæœºå™¨ç¿»è¯‘ï¼‰
- è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆæ–‡æœ¬åˆ†ç±»,è·¨è¯­è¨€ç†è§£ï¼‰
- é¢„è®­ç»ƒï¼ˆMLMã€TLMã€MASSï¼‰

æ”¯æŒç‰¹æ€§ï¼š
- Transformer
- Bert, XLM
- Distributed training(multi-node, multi-gpu)
- Classification(SST2, SST5)
- Fast beam search
- Average checkpoints and interactive inference



## âš™ï¸ å®‰è£…
```
git clone git@github.com:TenTrans/TenTrans.git
pip install -r requirements.txt 
```
Tentransæ˜¯ä¸€ä¸ªåŸºäºPytorchçš„è½»é‡çº§å·¥å…·åŒ…ï¼Œå®‰è£…ååˆ†æ–¹ä¾¿ã€‚

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹é¢„è®­ç»ƒæ¨¡å‹
TenTransæ”¯æŒå¤šç§é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŒ…æ‹¬åŸºäºç¼–ç å™¨çš„é¢„è®­ç»ƒï¼ˆe.g. MLMï¼‰å’ŒåŸºäºseq2seqç»“æ„çš„ç”Ÿæˆå¼é¢„è®­ç»ƒæ–¹æ³•ï¼ˆe.g. Massï¼‰ã€‚ æ­¤å¤–ï¼Œ Tentransè¿˜æ”¯æŒå¤§è§„æ¨¡çš„å¤šè¯­è¨€æœºå™¨ç¿»è¯‘é¢„è®­ç»ƒã€‚

æˆ‘ä»¬å°†ä»æœ€ç®€å•çš„MLMé¢„è®­ç»ƒå¼€å§‹ï¼Œè®©æ‚¨å¿«é€Ÿç†Ÿæ‚‰TenTransçš„è¿è¡Œé€»è¾‘ã€‚

1. æ•°æ®å¤„ç†

åœ¨é¢„è®­ç»ƒMLMæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å•è¯­è®­ç»ƒæ–‡ä»¶è¿›è¡ŒäºŒè¿›åˆ¶åŒ–ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤, è¯è¡¨çš„æ ¼å¼ä¸ºä¸€è¡Œä¸€è¯ï¼Œæ‰§è¡Œè¯¥å‘½ä»¤åä¼šç”Ÿæˆtrain.bpe.en.pthã€‚

```bash
python process.py vocab file  lang [shard_id](optional)
```

å½“æ•°æ®è§„æ¨¡ä¸å¤§æ—¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼çš„csvä½œä¸ºè®­ç»ƒæ–‡ä»¶ã€‚csvçš„æ–‡ä»¶æ ¼å¼ä¸º

| seq1 | lang1 |
| :--- |  ---: |
| This is a positive sentence. | en |
| This is a negtive sentence.| en |
| This is a  sentence.|  en |

2. å‚æ•°é…ç½®

TenTransæ˜¯é€šè¿‡yamlæ–‡ä»¶çš„æ–¹å¼è¯»å–è®­ç»ƒå‚æ•°çš„ï¼Œ æˆ‘ä»¬æä¾›äº†ä¸€ç³»åˆ—çš„é€‚åº”å„ä¸ªä»»åŠ¡çš„è®­ç»ƒé…ç½®æ–‡ä»¶æ¨¡ç‰ˆï¼ˆè§ **run/** æ–‡ä»¶å¤¹ï¼‰ï¼Œæ‚¨åªè¦æ”¹åŠ¨å¾ˆå°çš„ä¸€éƒ¨åˆ†å‚æ•°å³å¯ã€‚

```yaml
# base config
langs: [en]
epoch: 15
update_every_epoch:  1   # æ¯è½®æ›´æ–°å¤šå°‘step
dumpdir: ./dumpdir       # æ¨¡å‹åŠæ—¥å¿—æ–‡ä»¶ä¿å­˜çš„åœ°æ–¹
share_all_task_model: True # æ˜¯å¦å…±äº«æ‰€æœ‰ä»»åŠ¡çš„æ¨¡å‹å‚æ•°
save_intereval: 1      # æ¨¡å‹ä¿å­˜é—´éš”
log_interval: 10       # æ‰“å°æ—¥å¿—é—´éš”



#å…¨å±€è®¾ç½®å¼€å§‹ï¼Œ å¦‚æœtaskså†…æ²¡æœ‰å®šä¹‰ç‰¹å®šçš„å‚æ•°ï¼Œåˆ™å°†ä½¿ç”¨å…¨å±€è®¾ç½®
optimizer: adam 
learning_rate: 0.0001
learning_rate_warmup: 4000
scheduling: warmupexponentialdecay
max_tokens: 2000
group_by_size: False   # æ˜¯å¦å¯¹è¯­æ–™å¯¹é•¿åº¦æ’åº
max_seq_length: 260    # æ¨¡å‹æ‰€èƒ½æ¥å—çš„æœ€å¤§å¥å­é•¿åº¦
weight_decay: 0.01
eps: 0.000001
adam_betas: [0.9, 0.999]

sentenceRep:           # æ¨¡å‹ç¼–ç å™¨è®¾ç½®
  type: transformer #cbow, rnn
  hidden_size: 768
  ff_size: 3072
  dropout: 0.1
  attention_dropout: 0.1
  encoder_layers: 12
  num_lang: 1
  num_heads: 12
  use_langembed: False
  embedd_size: 768
  learned_pos: True
  pretrain_embedd: 
  activation: gelu
#å…¨å±€è®¾ç½®ç»“æŸ


tasks:                #ä»»åŠ¡å®šä¹‰ï¼Œ TenTransæ”¯æŒå¤šç§ä»»åŠ¡è”åˆè®­ç»ƒï¼ŒåŒ…æ‹¬åˆ†ç±»ï¼ŒMLMå’Œseq2seqè”åˆè®­ç»ƒã€‚
  en_mlm:             #ä»»åŠ¡IDï¼Œ  æ‚¨å¯ä»¥éšæ„å®šä¹‰æœ‰å«ä¹‰çš„æ ‡è¯†å
    task_name: mlm    #ä»»åŠ¡åï¼Œ  TenTransä¼šæ ¹æ®æŒ‡å®šçš„ä»»åŠ¡åè¿›è¡Œè®­ç»ƒ
    data:
        data_folder: your_data_folder
        src_vocab: vocab.txt
        # train_valid_test: [train.bpe.en.csv, valid.bpe.en.csv, test.bpe.en.csv]
        train_valid_test: [train.bpe.en.pth, valid.bpe.en.pth, test.bpe.en.pth]
        stream_text: False  # æ˜¯å¦å¯åŠ¨æ–‡æœ¬æµè®­ç»ƒ
        p_pred_mask_kepp_rand: [0.15, 0.8, 0.1, 0.1]

    target:           # è¾“å‡ºå±‚å®šä¹‰
        sentence_rep_dim: 768
        dropout: 0.1
        share_out_embedd: True
```
3. å¯åŠ¨è®­ç»ƒ

å•æœºå¤šå¡

```shell
export CUDA_VISIBLE_DEVICES=8;
python -m torch.distributed.launch \
                --nproc_per_node=$NPROC_PER_NODE main.py \
                --config run/xlm.yaml --multi_gpu True
```

##  ğŸ“‹ æ›´å¤šä»»åŠ¡
 - [æ–‡æœ¬åˆ†ç±»ï¼ˆSST2ï¼‰](examples/TASK/SST2.md) 
 - [æœºå™¨ç¿»è¯‘ï¼ˆWMT14ENDEï¼‰](examples/TASK/WMTENDE.md)

## ğŸ”‘ å¼€æºåè®®
æ­¤é¡¹ç›®éµå¾ªMITå¼€æºåè®®


## ğŸ™‹â€â™‚ï¸ è”ç³»æˆ‘ä»¬
å¦‚æœåœ¨ä½¿ç”¨æœ¬é¡¹ç›®è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜æˆ–æƒ³è¦è¿›ä¸€æ­¥çš„äº¤æµï¼Œå¯ä»¥è”ç³»Baijun Ji(begosu@foxmail.com; baijunji@tencent.com) ï¼ŒBojie Hu(bojiehu@tencent.com)ï¼ŒAmbyera(ambyera@tencent.comï¼‰ã€‚




